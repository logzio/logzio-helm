# Default values for logzio-telemetry.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

collector:
  mode: daemonset # possible values: standalone, daemonset
traces:
  enabled: false
metrics:
  enabled: false
spm:
  enabled: false

nameOverride: "otel-collector"
fullnameOverride: ""

secrets:
  MetricsToken: ""
  TracesToken: ""
  SpmToken: ""
  ListenerHost: ""
  env_id: "my_environment"
  LogzioRegion: "us"
  p8s_logzio_name: ""
  windowsNodeUsername: ""
  windowsNodePassword: ""
  SamplingProbability: 10
  SamplingLatency: 500


managedServiceAccount: true

clusterRole:
  # Specifies whether a clusterRole should be created
  create: false
  # Annotations to add to the clusterRole
  annotations: {}
  # The name of the clusterRole to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""
  # A set of rules as documented here : https://kubernetes.io/docs/reference/access-authn-authz/rbac/
  rules: []
  # - apiGroups:
  #   - ''
  #   resources:
  #   - 'pods'
  #   - 'nodes'
  #   verbs:
  #   - 'get'
  #   - 'list'
  #   - 'watch'
  clusterRoleBinding:
    # Annotations to add to the clusterRoleBinding
    annotations: {}
    # The name of the clusterRoleBinding to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

clusterRoleRules:
- apiGroups:
  - ""
  resources:
  - events
  - namespaces
  - namespaces/status
  - nodes
  - nodes/spec
  - pods
  - pods/metrics
  - nodes/metrics
  - pods/status
  - replicationcontrollers
  - replicationcontrollers/status
  - resourcequotas
  - services
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - daemonsets
  - deployments
  - replicasets
  - statefulsets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - daemonsets
  - deployments
  - replicasets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - jobs
  - cronjobs
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - get
  - list
  - watch

kubeStateMetrics:
  ## If false, kube-state-metrics sub-chart will not be installed
  ##
  enabled: true

pushGateway:
  ## If false, pushGateway sub-chart will not be installed
  ##
  enabled: true
prometheus-pushgateway:
  serviceAnnotations:
    prometheus.io/scrape: "true"
  nodeSelector:
    kubernetes.io/os: linux

nodeExporter:
  ## If false, node-exporter will not be installed
  ##
  enabled: true

emptyConfig: {}

baseCollectorConfig:
  exporters:
    logging:
      loglevel: info
  extensions:
    health_check: {}
  processors:
    k8sattributes:
      extract:
        metadata:
        - k8s.pod.name
        - k8s.deployment.name
        - k8s.namespace.name
        - k8s.node.name
    resource/k8s:
      attributes:
      # Rename
      - key: pod
        action: insert
        from_attribute: k8s.pod.name
      - key: kubernetes_node
        action: insert
        from_attribute: k8s.node.name
      - key: namespace
        action: insert
        from_attribute: k8s.namespace.name
      - key: deployment
        action: insert
        from_attribute: k8s.deployment.name
      - key: pod_ip
        action: insert
        from_attribute: k8s.pod.ip
      # Delete old
      - key: k8s.deployment.name
        action: delete
      - key: k8s.pod.name
        action: delete
      - key: k8s.namespace.name
        action: delete
      - key: k8s.node.name
        action: delete
      - key: k8s.pod.ip
        action: delete
    batch: {}
    attributes/env_id:
      actions:
        - key: env_id
          value: ${ENV_ID}
          action: insert
        - key: logzio_agent_version
          value: ${LOGZIO_AGENT_VERSION}
          action: insert
    memory_limiter: null
  service:
    extensions:
      - health_check
    telemetry:
      logs:
        level: "info"

tracesConfig:
  exporters:
    logzio:
      region: ${LOGZIO_LISTENER_REGION}
      account_token: ${TRACES_TOKEN}
    logging:
      loglevel: info
  extensions:
    pprof:
      endpoint: :1777
    zpages:
      endpoint: :55679
  receivers:
    jaeger:
      protocols:
        thrift_compact:
          endpoint: "0.0.0.0:6831"
        thrift_binary:
          endpoint: "0.0.0.0:6832"
        grpc:
          endpoint: "0.0.0.0:14250"
        thrift_http:
          endpoint: "0.0.0.0:14268"
    otlp:
      protocols:
        grpc:
          endpoint: "0.0.0.0:4317"
        http:
          endpoint: "0.0.0.0:4318"
    zipkin:
      endpoint: "0.0.0.0:9411"
  processors:
    tail_sampling:
      policies:
        [
            {
              name: error-in-policy,
              type: status_code,
              status_code: {status_codes: [ERROR]}
            },
            {
              name: slow-traces-policy,
              type: latency,
              latency: {threshold_ms: "${SAMPLING_LATENCY}" }            
            },
            {
              name: probability-policy,
              type: probabilistic,
              probabilistic: {sampling_percentage: "${SAMPLING_PROBABILITY}" }
            }       
        ]
  service:
    extensions:
      - health_check
      - pprof
      - zpages
    pipelines:
      traces:
        receivers: [jaeger, zipkin, otlp]
        processors: [tail_sampling, attributes/env_id, k8sattributes, resource/k8s, memory_limiter, batch]
        exporters: [logging, logzio]
    telemetry:
      logs:
        level: "info"  

spmForwarderConfig:
  exporters:
    otlp:
      endpoint: "${SPM_SERVICE_ENDPOINT}"
      tls:
        insecure: true
  service:
    pipelines:
      traces/spm:
        receivers: [jaeger, zipkin, otlp]
        processors: [attributes/env_id, memory_limiter, batch]
        exporters: [logging, otlp]

metricsConfig:
  extensions:
    health_check: {}
  processors:
    filter/kubernetes360:
      metrics:
        datapoint:
          - 'IsMatch(metric.name, "(${K8S_360_METRICS})") == true and attributes["logzio_app"] != "kubernetes360"'
  exporters:
    prometheusremotewrite:
      endpoint: ${LISTENER_URL}
      external_labels:
        p8s_logzio_name: ${P8S_LOGZIO_NAME}
      headers:
        Authorization: "Bearer ${METRICS_TOKEN}"
  receivers:
    prometheus:
      config:
        global:
          scrape_interval: 15s
          scrape_timeout: 10s
          evaluation_interval: 10s
        scrape_configs:
        # Job to collect opentelemetry collector metrics
        - job_name: 'collector-metrics'
          scrape_interval: 15s
          static_configs:
          - targets: [ "0.0.0.0:8888" ]
        - job_name: windows-metrics
          honor_timestamps: true
          honor_labels: true
          metrics_path: /metrics
          scheme: http
          kubernetes_sd_configs:
          - role: pod
          relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_windows_io_scrape]
              action: keep
              regex: true|"true"
          metric_relabel_configs: []
        - job_name: kubernetes-service-endpoints
          honor_timestamps: true
          honor_labels: true
          metrics_path: /metrics
          scheme: http
          kubernetes_sd_configs:
          - role: endpoints
          relabel_configs:
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
              action: keep
              regex: true|"true"
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
              action: replace
              target_label: __scheme__
              regex: (https?)
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
              action: replace
              target_label: __metrics_path__
              regex: (.+)
            - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
              action: replace
              target_label: __address__
              regex: ([^:]+)(?::\d+)?;(\d+)
              replacement: $$1:$$2
            - action: labelmap
              regex: __meta_kubernetes_service_label_(.+)
            - source_labels: [__meta_kubernetes_namespace]
              action: replace
              target_label: namespace
            - source_labels: [__meta_kubernetes_service_name]
              action: replace
              target_label: service
            - source_labels: [__meta_kubernetes_pod_name]
              action: replace
              target_label: pod
            - source_labels: [__meta_kubernetes_pod_node_name]
              action: replace
              target_label: kubernetes_node
            - source_labels: [__meta_kubernetes_service_annotation_logz_io_app]
              action: replace
              target_label: logzio_app
          metric_relabel_configs: []

        # Job to collect metrics from applications running on pods
        - job_name: applications
          honor_timestamps: true
          honor_labels: true
          metrics_path: /metrics
          scheme: http
          kubernetes_sd_configs:
          - role: pod
          relabel_configs:
            - action: keep
              regex: true|"true"
              source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            - action: replace
              regex: (https?)
              source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
              target_label: __scheme__
            - action: replace
              regex: (.+)
              source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
              target_label: __metrics_path__
            - action: replace
              regex: (.+?)(?::\d+)?;(\d+)
              replacement: $$1:$$2
              source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
              target_label: __address__
            - action: labelmap
              regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
              replacement: __param_$$1
            - action: labelmap
              regex: __meta_kubernetes_pod_label_(.+)
            - action: replace
              source_labels: [__meta_kubernetes_namespace]
              target_label: namespace
            - action: replace
              source_labels: [__meta_kubernetes_pod_name]
              target_label: pod
            - source_labels: [__meta_kubernetes_pod_node_name]
              action: replace
              target_label: kubernetes_node
        - job_name: 'kubernetes-cadvisor'
          scheme: https
          metrics_path: /metrics/cadvisor
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          kubernetes_sd_configs:
          - role: node
          relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)  
          metric_relabel_configs: []

  service:
    extensions:
      - health_check
    pipelines:
      metrics:
        exporters:
          - prometheusremotewrite
        processors:
          - attributes/env_id
          - memory_limiter
          - filter/kubernetes360
        receivers:
          - prometheus
          
# Shared params for agentCollector daemonset and standaloneCollector deployment pods.
# Can be overridden here or for any component independently using the same keys.

image:
  # If you want to use the contrib image `otel/opentelemetry-collector-contrib`, you also need to change `command.name` value to `otelcontribcol`.
  repository: otel/opentelemetry-collector-contrib
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "0.70.0"
nginxWindowsImage:
  # Reverse proxy image to enable metrics scraping from windows nodes
  repository: logzio/logzio-windows-node-reverse-proxy
  pullPolicy: IfNotPresent
  tag: "0.0.1"
windowsExporterInstallerImage:
  # Job image to install windows exporter on windows nodes
  repository: logzio/logzio-windows-exporter-installer
  pullPolicy: IfNotPresent
  tag: "0.0.1"
imagePullSecrets: []

# OpenTelemetry Collector executable
command:
  name: otelcol-contrib
  extraArgs: []

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podSecurityContext: {}
securityContext: {}

nodeSelector: {}
linuxNodeSelector: {
  "kubernetes.io/os": linux
}

tolerations: []

affinity: {}

extraEnvs: []
extraHostPathMounts: []
secretMounts: []

# Configuration for ports, shared between agentCollector, standaloneCollector and service.
# Can be overridden here or for agentCollector and standaloneCollector independently.
ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
    protocol: TCP
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    hostPort: 4318
    protocol: TCP
  jaeger-compact:
    enabled: true
    containerPort: 6831
    servicePort: 6831
    hostPort: 6831
    protocol: UDP
  jaeger-thrift:
    enabled: true
    containerPort: 14268
    servicePort: 14268
    hostPort: 14268
    protocol: TCP
  jaeger-grpc:
    enabled: true
    containerPort: 14250
    servicePort: 14250
    hostPort: 14250
    protocol: TCP
  zipkin:
    enabled: true
    containerPort: 9411
    servicePort: 9411
    hostPort: 9411
    protocol: TCP

spanMetricsAgregator:
  config:
    processors:
      spanmetrics:
        metrics_exporter: prometheus/spm
        latency_histogram_buckets: [2ms, 8ms, 50ms, 100ms, 200ms, 500ms, 1s, 5s, 10s]
        dimensions_cache_size: 100000
        aggregation_temporality: AGGREGATION_TEMPORALITY_CUMULATIVE
        dimensions:
          - name: http.method
          - name: env_id
            default: ${ENV_ID}
    receivers:
      # Dummy recivier 
      otlp/spm:
        protocols:
          grpc:
            endpoint: "localhost:12345"
      prometheus/spm-logzio:
        config:
          scrape_configs:
          - job_name: 'spm'
            scrape_interval: 15s
            static_configs:
            - targets: [ "0.0.0.0:8889" ]
      jaeger:
        protocols:
          thrift_compact:
            endpoint: "0.0.0.0:6831"
          thrift_binary:
            endpoint: "0.0.0.0:6832"
          grpc:
            endpoint: "0.0.0.0:14250"
          thrift_http:
            endpoint: "0.0.0.0:14268"
      otlp:
        protocols:
          grpc:
            endpoint: "0.0.0.0:4317"
          http:
            endpoint: "0.0.0.0:4318"
      zipkin:
        endpoint: "0.0.0.0:9411"
    exporters:
      logging: {}
      prometheus/spm:
        endpoint: "0.0.0.0:8889"
      prometheusremotewrite/spm-logzio:
        endpoint: ${LISTENER_URL}
        headers:
          Authorization: "Bearer ${SPM_TOKEN}"
    service:
      pipelines:
        traces:
          receivers: [jaeger, zipkin, otlp]
          processors: [spanmetrics]
          exporters: [logging]
        metrics/spm:
          # Dummy recivier 
          receivers: [otlp/spm ]
          exporters: [logging, prometheus/spm]
        metrics/spm-logzio:
          receivers: [prometheus/spm-logzio]
          exporters: [prometheusremotewrite/spm-logzio]
  # service values        
  service:
    type: ClusterIP
    annotations: {}
  ports:
    otlp:
      enabled: true
      containerPort: 4317
      servicePort: 4317
      hostPort: 4317
      protocol: TCP
    otlp-http:
      enabled: true
      containerPort: 4318
      servicePort: 4318
      hostPort: 4318
      protocol: TCP
    jaeger-compact:
      enabled: true
      containerPort: 6831
      servicePort: 6831
      hostPort: 6831
      protocol: UDP
    jaeger-thrift:
      enabled: true
      containerPort: 14268
      servicePort: 14268
      hostPort: 14268
      protocol: TCP
    jaeger-grpc:
      enabled: true
      containerPort: 14250
      servicePort: 14250
      hostPort: 14250
      protocol: TCP
    zipkin:
      enabled: true
      containerPort: 9411
      servicePort: 9411
      hostPort: 9411
      protocol: TCP
  resources:
    limits:
      cpu: 256m
      memory: 512Mi

# Configuration for agent OpenTelemetry Collector daemonset, disabled by default
agentCollector:
  enabled: false

  containerLogs:
    enabled: false

  resources:
    limits:
      cpu: 256m
      memory: 512Mi
  podAnnotations: {}
  # Configuration override that will be merged into the agent's default config
  configOverride: {}
# Configuration for standalone OpenTelemetry Collector deployment, enabled by default
standaloneCollector:
  enabled: false

  containerLogs:
    enabled: false

  resources:
    limits:
      cpu: 512m
      memory: 1024Mi

  podAnnotations: {}
  # Configuration override that will be merged into the agent's default config
  configOverride: {}

daemonsetCollector:
  enabled: false

  containerLogs:
    enabled: false
  
  # prevent collector daemonset deployment on fargate nodes
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: eks.amazonaws.com/compute-type
                operator: DoesNotExist

  resources:
    limits:
      cpu: 512m
      memory: 1024Mi

  podAnnotations: {}
  # Configuration override that will be merged into the agent's default config
  configOverride: {}

service:
  type: ClusterIP
  annotations: {}

# autoscaling is used only if standaloneCollector enabled
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

windowsExporterInstallerJob:
  interval: "*/10 * * * *"
  concurrencyPolicy: Forbid            # Future cronjob will run only after current job is finished
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 1
  ttlSecondsAfterFinished: 3600        # First job only (Not CronJob)   

# /*Otel traces additions*/ 

podMonitor:
  enabled: false
  metricsEndpoints: {}
  # - port: prometheus
  # additional labels for the PodMonitor
  extraLabels: {}
  #   release: kube-prometheus-stack
serviceMonitor:
  enabled: false
  metricsEndpoints: {}
  # - port: metrics
  #   interval: 15s
  # additional labels for the ServiceMonitor
  extraLabels: {}
  #  release: kube-prometheus-stack

podLabels:  {}
annotations:  {}

kube-state-metrics:
  service:
    annotations:
      prometheus.io/scrape: "true"
      logz.io/app: "kubernetes360"
  nodeSelector:
    kubernetes.io/os: linux
  podSecurityPolicy:
    enabled: false

prometheus-node-exporter:
  service:
    port: 9101
    targetPort: 9101
    annotations:
      prometheus.io/scrape: "true"
      logz.io/app: "kubernetes360"
  nodeSelector:
    kubernetes.io/os: linux
  # Prevent node exporter deamonset deploymment on fargate nodes
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: eks.amazonaws.com/compute-type
                operator: DoesNotExist
  rbac:
    pspEnabled: false

enableMetricsFilter:
  gke: false
  eks: false
  aks: false
  kubeSystem: false

disableKubeDnsScraping: false

daemonsetConfig:
  extensions:
    health_check: {}
  processors:
    filter/kubernetes360:
      metrics:
        datapoint:
          - 'IsMatch(metric.name, "(${K8S_360_METRICS})") == true and attributes["logzio_app"] != "kubernetes360"'
          - 'IsMatch(metric.name, "(${K8S_360_METRICS})") == true and IsMatch(attributes["kubernetes_node"], "(.+)") == false'
    filter/endpoints:
      metrics:
        datapoint:
  exporters:
    prometheusremotewrite:
      endpoint: ${LISTENER_URL}
      external_labels:
        p8s_logzio_name: ${P8S_LOGZIO_NAME}
      headers:
        Authorization: "Bearer ${METRICS_TOKEN}"
  receivers:
    prometheus:
      config:
        global:
          scrape_interval: 15s
          scrape_timeout: 10s
          evaluation_interval: 10s
        scrape_configs:
        # Job to collect opentelemetry collector metrics
        - job_name: 'collector-metrics'
          scrape_interval: 15s
          static_configs:
          - targets: [ "0.0.0.0:8888" ]
        - job_name: windows-metrics
          honor_timestamps: true
          honor_labels: true
          metrics_path: /metrics
          scheme: http
          kubernetes_sd_configs:
          - role: pod
            selectors:
            # only scrape data from pods running on the same node as collector
            - role: pod
              field: "spec.nodeName=$KUBE_NODE_NAME"
          relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_windows_io_scrape]
              action: keep
              regex: true|"true"
          metric_relabel_configs: []
        # Job to collect metrics from applications running on pods
        - job_name: kubernetes-service-endpoints
          honor_timestamps: true
          honor_labels: true
          metrics_path: /metrics
          scheme: http
          kubernetes_sd_configs:
          - role: endpoints
            selectors:
            # only scrape data from pods running on the same node as collector
            - role: pod
              field: "spec.nodeName=$KUBE_NODE_NAME"
          relabel_configs:
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
              action: keep
              regex: true|"true"
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
              action: replace
              target_label: __scheme__
              regex: (https?)
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
              action: replace
              target_label: __metrics_path__
              regex: (.+)
            - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
              action: replace
              target_label: __address__
              regex: ([^:]+)(?::\d+)?;(\d+)
              replacement: $$1:$$2
            - action: labelmap
              regex: __meta_kubernetes_service_label_(.+)
            - source_labels: [__meta_kubernetes_namespace]
              action: replace
              target_label: namespace
            - source_labels: [__meta_kubernetes_service_name]
              action: replace
              target_label: service
            - source_labels: [__meta_kubernetes_pod_name]
              action: replace
              target_label: pod
            - source_labels: [__meta_kubernetes_pod_node_name]
              action: replace
              target_label: kubernetes_node
            - source_labels: [__meta_kubernetes_service_annotation_logz_io_app]
              action: replace
              target_label: logzio_app                 
          metric_relabel_configs: []
        - job_name: 'kubernetes-cadvisor'
          scheme: https
          metrics_path: /metrics/cadvisor
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          kubernetes_sd_configs:
          - role: node
            selectors:
            # only scrape data from node with the same name as the node the collector run on
            - role: node
              field: "metadata.name=$KUBE_NODE_NAME"
          relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)  
          metric_relabel_configs: []

  service:
    extensions:
      - health_check
    pipelines:
      metrics:
        exporters:
          - prometheusremotewrite
        processors:
          - attributes/env_id
          - memory_limiter
          - filter/kubernetes360
        receivers:
          - prometheus
          
opencost:
  enabled: false
  config:
    processors:
    # opencost collects duplicates metrics from kube-state and cadvisor.
      filter/opencost-exporter: 
        metrics:
          datapoint:     
            - 'IsMatch(metric.name, "(${OPENCOST_DUPLICATES})") == true and attributes["app"] == "opencost"'
    service:
      pipelines:
        metrics:
          processors:
            - filter/opencost-exporter


